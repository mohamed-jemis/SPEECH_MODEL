{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nimport pickle\nimport re\nimport librosa\nimport librosa.display\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom tqdm import tqdm\nimport soundfile\nfrom keras.layers import Dense, Conv2D, MaxPool2D , Flatten, BatchNormalization, Dropout, ELU, LSTM, Reshape\nfrom keras.models import Model, Sequential\nfrom keras.applications import VGG16, Xception\nfrom tensorflow.keras.optimizers.legacy import Adam\nfrom sklearn.preprocessing import OneHotEncoder\nimport keras\nfrom scipy.io import wavfile\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-01T21:41:54.516678Z","iopub.execute_input":"2023-03-01T21:41:54.517120Z","iopub.status.idle":"2023-03-01T21:42:04.987164Z","shell.execute_reply.started":"2023-03-01T21:41:54.517033Z","shell.execute_reply":"2023-03-01T21:42:04.986040Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Global Variables","metadata":{}},{"cell_type":"code","source":"sr = 16000\nseg_size = 8\n\nemotion_dict = {'ang': 0,\n                'hap': 1,\n                'exc': 2,\n                'sad': 3,\n                'fru': 4,\n                'fea': 5,\n                'sur': 6,\n                'neu': 7,\n                'dis': 8,\n                'xxx': 9,\n                'oth': 9}","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:42:04.989350Z","iopub.execute_input":"2023-03-01T21:42:04.990108Z","iopub.status.idle":"2023-03-01T21:42:04.997320Z","shell.execute_reply.started":"2023-03-01T21:42:04.990064Z","shell.execute_reply":"2023-03-01T21:42:04.996045Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Reading Labels","metadata":{}},{"cell_type":"code","source":"def read_labels(datapath):\n    info_line = re.compile(r'\\[.+\\]\\n', re.IGNORECASE)\n\n    start_times, end_times, wav_file_names, emotions, vals, acts, doms = [], [], [], [], [], [], []\n\n    evaluation_files = [l for l in os.listdir(datapath) if 'Ses' in l]\n    for file in evaluation_files:\n        with open(datapath + file) as f:\n            content = f.read()\n\n        info_lines = re.findall(info_line, content)\n\n        for line in info_lines[1:]:  # the first line is a header\n            start_end_time, wav_file_name, emotion, val_act_dom = line.strip().split('\\t')\n            start_time, end_time = start_end_time[1:-1].split('-')\n\n            val, act, dom = val_act_dom[1:-1].split(',')\n            val, act, dom = float(val), float(act), float(dom)\n\n            start_time, end_time = float(start_time), float(end_time)\n\n            start_times.append(start_time)\n            end_times.append(end_time)\n            wav_file_names.append(wav_file_name)\n            emotions.append(emotion)\n            vals.append(val)\n            acts.append(act)\n            doms.append(dom)\n\n    df_iemocap = pd.DataFrame(columns=['start_time', 'end_time', 'wav_file', 'emotion', 'val', 'act', 'dom'])\n\n    df_iemocap['start_time'] = start_times\n    df_iemocap['end_time'] = end_times\n    df_iemocap['wav_file'] = wav_file_names\n    df_iemocap['emotion'] = emotions\n    df_iemocap['val'] = vals\n    df_iemocap['act'] = acts\n    df_iemocap['dom'] = doms\n\n    df_iemocap.to_csv('df_iemocap.csv', index=False)\n\n    return df_iemocap","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:42:04.999132Z","iopub.execute_input":"2023-03-01T21:42:05.000113Z","iopub.status.idle":"2023-03-01T21:42:05.012987Z","shell.execute_reply.started":"2023-03-01T21:42:05.000068Z","shell.execute_reply":"2023-03-01T21:42:05.011848Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Reading audio files","metadata":{}},{"cell_type":"code","source":"def read_audio(wav_file_path, labels_df):\n\n    audio_vectors = {}\n    orig_wav_files = os.listdir(wav_file_path)\n    \n    for orig_wav_file in tqdm(orig_wav_files):\n\n        #samplerate, orig_wav_vector = wavfile.read(wav_file_path + orig_wav_file)\n        orig_wav_vector, samplerate = librosa.load(wav_file_path + orig_wav_file, sr=sr, mono=False)\n\n        left = orig_wav_vector[0]\n        right = orig_wav_vector[1]\n\n        orig_wav_file, file_format = orig_wav_file.split('.')\n\n        for index, row in labels_df[labels_df['wav_file'].str.contains(orig_wav_file)].iterrows():\n\n            start, end, truncated_wav_file_name, emotion, val, act, dom = row['start_time'], row[\n                'end_time'], row['wav_file'], row['emotion'], row['val'], row['act'], row['dom']\n\n            frames = []\n\n            fright = right[int(start * samplerate):int(end * samplerate)]\n            fleft = left[int(start * samplerate):int(end * samplerate)]\n\n            length = int(fright.shape[0] / samplerate)\n\n            if length > seg_size:\n                for i in range(math.ceil(length/seg_size)):\n\n                    start_f = i * seg_size\n                    end_f = start_f + seg_size\n\n                    if i == math.ceil(length/seg_size) - 1 and int(length/seg_size) == i:\n                        end_f = length\n                        start_f = length - seg_size\n                    \n                    frames.append(fright[int(start_f * samplerate):int(end_f * samplerate)])\n                    frames.append(fleft[int(start_f * samplerate):int(end_f * samplerate)])\n                    \n\n            elif length < seg_size:\n                padded_fl = np.pad(fleft, ((length%2) * samplerate, math.floor((seg_size-length)/2)* 2 * samplerate), 'mean')\n                padded_fr = np.pad(fright, ((length%2) * samplerate, math.floor((seg_size-length)/2)* 2 * samplerate), 'mean')\n\n                frames.append(padded_fl[:seg_size * samplerate])\n                frames.append(padded_fr[:seg_size * samplerate])\n\n            else:\n                frames.append(fright[:seg_size * samplerate])\n                frames.append(fleft[:seg_size * samplerate])\n            \n            \n            audio_vectors[truncated_wav_file_name] = frames\n                \n\n    with open('audio_vectors1.pkl', 'wb') as f:\n        pickle.dump(audio_vectors, f)\n\n    return audio_vectors\n","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:42:05.016202Z","iopub.execute_input":"2023-03-01T21:42:05.016613Z","iopub.status.idle":"2023-03-01T21:42:05.033068Z","shell.execute_reply.started":"2023-03-01T21:42:05.016552Z","shell.execute_reply":"2023-03-01T21:42:05.031932Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Extracting features","metadata":{}},{"cell_type":"code","source":"def extract_audio_features(audio_vectors, labels_df, emotion_dict):\n    file_name, x, y = [], [], []\n    i=0\n    for index, row in tqdm(labels_df.iterrows()):\n        i+=1\n        wav_file_name = row['wav_file']\n        label = emotion_dict[row['emotion']]\n        audio = audio_vectors[wav_file_name]\n    \n        for frame in audio:\n            mfcc = np.array(librosa.feature.mfcc(y=frame, sr=sr))\n            mfcc_mean = mfcc.mean(axis=1)\n            mfcc_min = mfcc.min(axis=1)\n            mfcc_max = mfcc.max(axis=1)\n            mfcc_feature = np.concatenate( (mfcc_mean, mfcc_min, mfcc_max) )\n     \n            file_name.append(wav_file_name)\n            x.append(mfcc_feature.reshape(1, -1).tolist()[0])\n            y.append(label)\n        \n        if i == 267:\n            break\n    \n    df = pd.concat([pd.DataFrame(file_name, columns=[\"file_name\"]), pd.DataFrame(x), pd.DataFrame(y, columns=[\"label\"])], axis=1)\n    #df.to_csv('audios_features.csv', index=False)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:42:05.036092Z","iopub.execute_input":"2023-03-01T21:42:05.036477Z","iopub.status.idle":"2023-03-01T21:42:05.050602Z","shell.execute_reply.started":"2023-03-01T21:42:05.036448Z","shell.execute_reply":"2023-03-01T21:42:05.049611Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def preprocess(audio_vectors, labels_df, emotion_dict):\n    file_name, x, y = [], [], []\n    i=0\n    for index, row in tqdm(labels_df.iterrows()):\n        i+=1\n        wav_file_name = row['wav_file']\n        label = emotion_dict[row['emotion']]\n        audio = audio_vectors[wav_file_name]\n    \n        for frame in audio:\n            file_name.append(wav_file_name)\n            x.append(frame.reshape(1, -1).tolist()[0])\n            y.append(label)\n        if i == 1000:\n            break\n    df = pd.concat([pd.DataFrame(file_name, columns=[\"file_name\"]), pd.DataFrame(x), pd.DataFrame(y, columns=[\"label\"])], axis=1)\n    df.to_csv('audios_features.csv', index=False)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:42:05.051997Z","iopub.execute_input":"2023-03-01T21:42:05.052604Z","iopub.status.idle":"2023-03-01T21:42:05.065858Z","shell.execute_reply.started":"2023-03-01T21:42:05.052565Z","shell.execute_reply":"2023-03-01T21:42:05.064727Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def features_2d(audio_vectors, labels_df, emotion_dict):\n    file_name, x, y = [], [], []\n    i=0\n    for index, row in tqdm(labels_df.iterrows()):\n        i+=1\n        wav_file_name = row['wav_file']\n        label = emotion_dict[row['emotion']]\n        audio = audio_vectors[wav_file_name]\n    \n        for frame in audio:\n            mfcc = np.array(librosa.feature.mfcc(y=frame, sr=sr, n_mfcc=128))\n            chroma = np.array(librosa.feature.chroma_stft(y=frame, sr=sr, n_chroma=128))\n            mel = np.array(librosa.feature.melspectrogram(y=frame, sr=sr, n_mels=128))\n            \n            mel = librosa.power_to_db(mel)\n            mel = mel.astype(np.float32)\n            \n            chroma = librosa.power_to_db(chroma)\n            chroma = chroma.astype(np.float32)\n            \n            mfcc = librosa.power_to_db(mfcc)\n            mfcc = mfcc.astype(np.float32)\n            \n            file_name.append(wav_file_name)\n            feature = [mfcc, chroma, mel]\n            x.append(feature)\n            y.append(label)\n        \n#         if i == 16:\n#             break\n    \n    x = np.array(x).reshape(-1, mel.shape[0], mel.shape[1], 3)\n    print(x.shape)\n    # df = pd.concat([pd.DataFrame(file_name, columns=[\"file_name\"]), pd.DataFrame(x), pd.DataFrame(y, columns=[\"label\"])], axis=1)\n    # df.to_csv('audios_features.csv', index=False)\n    \n    with open('x1.pkl', 'wb') as f:\n        pickle.dump(x, f)\n        \n    with open('y1.pkl', 'wb') as f:\n        pickle.dump(y, f)\n        \n    print('done')\n    \n    return x, y, mel.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:42:05.067788Z","iopub.execute_input":"2023-03-01T21:42:05.068516Z","iopub.status.idle":"2023-03-01T21:42:05.080620Z","shell.execute_reply.started":"2023-03-01T21:42:05.068475Z","shell.execute_reply":"2023-03-01T21:42:05.079505Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Keras Model","metadata":{}},{"cell_type":"code","source":"def create_model(input_shape, n_units):\n    model = Sequential()\n    model.add(Input(shape=input_shape))\n    \n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    \n    model.add(Dropout(0.5))\n \n    model.add(Dense(units=n_units, activation=\"softmax\"))\n    \n    opt = Adam(learning_rate=0.1)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:42:05.082055Z","iopub.execute_input":"2023-03-01T21:42:05.082455Z","iopub.status.idle":"2023-03-01T21:42:05.097054Z","shell.execute_reply.started":"2023-03-01T21:42:05.082418Z","shell.execute_reply":"2023-03-01T21:42:05.095910Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def create_model2(input_shape, n_units):\n    model = Sequential()\n    model.add(Input(shape=input_shape))\n    \n    model.add(Flatten())\n\n    model.add(Dense(1024, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(1024, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(1024, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(1024, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(1024, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(units=n_units, activation=\"softmax\"))\n    \n    opt = Adam(learning_rate=0.01)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:42:05.098631Z","iopub.execute_input":"2023-03-01T21:42:05.099053Z","iopub.status.idle":"2023-03-01T21:42:05.112337Z","shell.execute_reply.started":"2023-03-01T21:42:05.099017Z","shell.execute_reply":"2023-03-01T21:42:05.111198Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def convNet(shape, n_units):\n    model = Sequential()\n\n    model.add(Conv2D(input_shape=shape, filters=16, kernel_size=(5,5), strides=(2,2), activation='relu'))\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), activation='relu'))\n    model.add(BatchNormalization())\n    \n    model.add(Flatten())\n\n    model.add(Dense(units=716,activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(units=716,activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(units=n_units, activation=\"softmax\"))\n    adam = Adam(lr=0.001)\n\n    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'], run_eagerly=True)\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:42:05.115857Z","iopub.execute_input":"2023-03-01T21:42:05.116160Z","iopub.status.idle":"2023-03-01T21:42:05.126556Z","shell.execute_reply.started":"2023-03-01T21:42:05.116134Z","shell.execute_reply":"2023-03-01T21:42:05.125525Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def vgg16(shape, n_units):\n    base_model = VGG16(weights = \"imagenet\", include_top=False, input_shape = shape)\n    base_model.trainable = False\n    inputs = keras.Input(shape=shape)\n    \n    model = Sequential()\n    \n    model.add(base_model)\n    \n    model.add(Flatten())\n\n    model.add(Dense(units=32,activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(units=16,activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(units=n_units, activation=\"softmax\"))\n    adam = Adam(lr=0.1)\n\n    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'], run_eagerly=True)\n\n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:42:05.129062Z","iopub.execute_input":"2023-03-01T21:42:05.130070Z","iopub.status.idle":"2023-03-01T21:42:05.143389Z","shell.execute_reply.started":"2023-03-01T21:42:05.130040Z","shell.execute_reply":"2023-03-01T21:42:05.142287Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def cnn_lstm(shape, n_units):\n    model = Sequential()\n    \n    # 1\n    model.add(Conv2D(input_shape=shape, filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n    model.add(BatchNormalization())\n    model.add(ELU())\n    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n    \n    #2\n    model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n    model.add(BatchNormalization())\n    model.add(ELU())\n    model.add(MaxPool2D(pool_size=(4, 4), strides=(4, 4)))\n    \n    #3\n    model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same'))\n    model.add(BatchNormalization())\n    model.add(ELU())\n    model.add(MaxPool2D(pool_size=(4, 4), strides=(4, 4)))\n    \n    #4\n    model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same'))\n    model.add(BatchNormalization())\n    model.add(ELU())\n    model.add(MaxPool2D(pool_size=(4, 4), strides=(4, 4)))\n    \n    #Reshape output for lstm\n    model.add(Reshape((-1,128)))\n    \n    #LSTM\n    model.add(LSTM(units=256, return_sequences=True))\n    \n    #Softmax\n    model.add(Flatten())\n    model.add(Dense(units=n_units, activation=\"softmax\"))\n    adam = Adam(lr=0.01)\n\n    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'], run_eagerly=True)\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:42:05.144836Z","iopub.execute_input":"2023-03-01T21:42:05.145303Z","iopub.status.idle":"2023-03-01T21:42:05.158448Z","shell.execute_reply.started":"2023-03-01T21:42:05.145260Z","shell.execute_reply":"2023-03-01T21:42:05.157329Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Code and trainig","metadata":{}},{"cell_type":"code","source":"labels_path = '/kaggle/input/iemocapfullrelease/IEMOCAP_full_release/Session1/dialog/EmoEvaluation/'\nwav_path = '/kaggle/input/iemocapfullrelease/IEMOCAP_full_release/Session1/dialog/wav/'\n# read the pickle and the csv\n\nlabels_df = pd.read_csv(\"/kaggle/working/df_iemocap.csv\")\n#audio_vectors = pickle.load(open('/kaggle/working/audio_vectors1.pkl', 'rb'))\n#labeled_features_df = pd.read_csv(\"/kaggle/working/audios_features.csv\")\n\n# labels_df = read_labels(labels_path)\naudio_vectors = read_audio(wav_path, labels_df)\n\n#labeled_features_df = extract_audio_features(audio_vectors, labels_df, emotion_dict)\n#labeled_features_df = preprocess(audio_vectors, labels_df, emotion_dict)\n\n# x = pickle.load(open('/kaggle/working/x1.pkl', 'rb'))\n# y = pickle.load(open('/kaggle/working/y1.pkl', 'rb'))\n\nx, y, shape = features_2d(audio_vectors, labels_df, emotion_dict)\n\n#x = labeled_features_df.drop(columns=['label', 'file_name'])\n\nenc = OneHotEncoder()\ny = enc.fit_transform(np.asarray(y).reshape(-1,1)).toarray()\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\n#### MLP MODEL\n#model = MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n# # print(x_train[0].shape)\n# x_train = np.array(x_train).reshape(-1,1)\n# y_train = np.array(y_train).reshape(-1,1)\n#print('shape is ',x_train.shape,' ',y_train.shape)\n\n# model.fit(x_train, y_train)\n# y_pred = model.predict(x_test)\n# accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n# print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n\nprint('create model')\nmodel = cnn_lstm((shape[0], shape[1], 3), len(y[0]))\nmodel.build()\nprint(model.summary())\nprint('fit model')\n\nmodel.fit(x_train, y_train, epochs = 100, verbose=1, validation_data=(x_test, y_test), steps_per_epoch = len(x_train) // 32)","metadata":{"execution":{"iopub.status.busy":"2023-03-01T21:42:05.159919Z","iopub.execute_input":"2023-03-01T21:42:05.160628Z","iopub.status.idle":"2023-03-01T22:08:13.228386Z","shell.execute_reply.started":"2023-03-01T21:42:05.160589Z","shell.execute_reply":"2023-03-01T22:08:13.227243Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"100%|██████████| 28/28 [00:10<00:00,  2.76it/s]\n1819it [07:20,  4.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"(4000, 128, 251, 3)\ndone\ncreate model\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 128, 251, 64)      1792      \n                                                                 \n batch_normalization (BatchN  (None, 128, 251, 64)     256       \n ormalization)                                                   \n                                                                 \n elu (ELU)                   (None, 128, 251, 64)      0         \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 64, 125, 64)      0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 64, 125, 64)       36928     \n                                                                 \n batch_normalization_1 (Batc  (None, 64, 125, 64)      256       \n hNormalization)                                                 \n                                                                 \n elu_1 (ELU)                 (None, 64, 125, 64)       0         \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 16, 31, 64)       0         \n 2D)                                                             \n                                                                 \n conv2d_2 (Conv2D)           (None, 16, 31, 128)       73856     \n                                                                 \n batch_normalization_2 (Batc  (None, 16, 31, 128)      512       \n hNormalization)                                                 \n                                                                 \n elu_2 (ELU)                 (None, 16, 31, 128)       0         \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 4, 7, 128)        0         \n 2D)                                                             \n                                                                 \n conv2d_3 (Conv2D)           (None, 4, 7, 128)         147584    \n                                                                 \n batch_normalization_3 (Batc  (None, 4, 7, 128)        512       \n hNormalization)                                                 \n                                                                 \n elu_3 (ELU)                 (None, 4, 7, 128)         0         \n                                                                 \n max_pooling2d_3 (MaxPooling  (None, 1, 1, 128)        0         \n 2D)                                                             \n                                                                 \n reshape (Reshape)           (None, 1, 128)            0         \n                                                                 \n lstm (LSTM)                 (None, 1, 256)            394240    \n                                                                 \n flatten (Flatten)           (None, 256)               0         \n                                                                 \n dense (Dense)               (None, 10)                2570      \n                                                                 \n=================================================================\nTotal params: 658,506\nTrainable params: 657,738\nNon-trainable params: 768\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(Adam, self).__init__(name, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"None\nfit model\nEpoch 1/100\n200/200 [==============================] - 19s 59ms/step - loss: 1.9524 - accuracy: 0.2384 - val_loss: 2.1470 - val_accuracy: 0.2087\nEpoch 2/100\n200/200 [==============================] - 11s 56ms/step - loss: 1.8376 - accuracy: 0.2675 - val_loss: 2.0143 - val_accuracy: 0.2438\nEpoch 3/100\n200/200 [==============================] - 11s 54ms/step - loss: 1.8198 - accuracy: 0.2637 - val_loss: 1.8114 - val_accuracy: 0.2725\nEpoch 4/100\n200/200 [==============================] - 10s 52ms/step - loss: 1.7910 - accuracy: 0.2859 - val_loss: 1.7473 - val_accuracy: 0.3025\nEpoch 5/100\n200/200 [==============================] - 11s 56ms/step - loss: 1.7806 - accuracy: 0.2941 - val_loss: 1.7679 - val_accuracy: 0.3137\nEpoch 6/100\n200/200 [==============================] - 11s 54ms/step - loss: 1.7699 - accuracy: 0.2991 - val_loss: 1.7607 - val_accuracy: 0.2800\nEpoch 7/100\n200/200 [==============================] - 10s 52ms/step - loss: 1.7578 - accuracy: 0.2966 - val_loss: 1.8808 - val_accuracy: 0.2575\nEpoch 8/100\n200/200 [==============================] - 11s 53ms/step - loss: 1.7506 - accuracy: 0.3006 - val_loss: 1.8479 - val_accuracy: 0.2862\nEpoch 9/100\n200/200 [==============================] - 11s 57ms/step - loss: 1.7551 - accuracy: 0.3100 - val_loss: 1.7952 - val_accuracy: 0.2875\nEpoch 10/100\n200/200 [==============================] - 11s 53ms/step - loss: 1.7567 - accuracy: 0.3056 - val_loss: 1.8770 - val_accuracy: 0.2600\nEpoch 11/100\n200/200 [==============================] - 10s 52ms/step - loss: 1.7384 - accuracy: 0.3147 - val_loss: 1.7375 - val_accuracy: 0.3262\nEpoch 12/100\n200/200 [==============================] - 11s 54ms/step - loss: 1.7199 - accuracy: 0.3156 - val_loss: 1.8162 - val_accuracy: 0.2937\nEpoch 13/100\n200/200 [==============================] - 11s 53ms/step - loss: 1.7139 - accuracy: 0.3184 - val_loss: 1.7402 - val_accuracy: 0.3050\nEpoch 14/100\n200/200 [==============================] - 11s 53ms/step - loss: 1.6925 - accuracy: 0.3334 - val_loss: 1.7164 - val_accuracy: 0.3212\nEpoch 15/100\n200/200 [==============================] - 11s 54ms/step - loss: 1.6975 - accuracy: 0.3325 - val_loss: 1.7287 - val_accuracy: 0.3137\nEpoch 16/100\n200/200 [==============================] - 10s 52ms/step - loss: 1.6816 - accuracy: 0.3484 - val_loss: 1.7448 - val_accuracy: 0.3262\nEpoch 17/100\n200/200 [==============================] - 11s 53ms/step - loss: 1.6802 - accuracy: 0.3431 - val_loss: 1.7900 - val_accuracy: 0.3013\nEpoch 18/100\n200/200 [==============================] - 11s 54ms/step - loss: 1.6554 - accuracy: 0.3481 - val_loss: 1.7355 - val_accuracy: 0.3363\nEpoch 19/100\n200/200 [==============================] - 11s 53ms/step - loss: 1.6441 - accuracy: 0.3641 - val_loss: 1.7460 - val_accuracy: 0.3250\nEpoch 20/100\n200/200 [==============================] - 11s 53ms/step - loss: 1.6246 - accuracy: 0.3659 - val_loss: 1.7515 - val_accuracy: 0.3113\nEpoch 21/100\n200/200 [==============================] - 11s 53ms/step - loss: 1.6142 - accuracy: 0.3787 - val_loss: 1.7984 - val_accuracy: 0.3075\nEpoch 22/100\n200/200 [==============================] - 11s 53ms/step - loss: 1.5791 - accuracy: 0.3884 - val_loss: 1.7503 - val_accuracy: 0.3262\nEpoch 23/100\n200/200 [==============================] - 11s 53ms/step - loss: 1.5739 - accuracy: 0.3828 - val_loss: 1.7469 - val_accuracy: 0.3250\nEpoch 24/100\n200/200 [==============================] - 11s 57ms/step - loss: 1.5338 - accuracy: 0.4072 - val_loss: 1.8520 - val_accuracy: 0.3137\nEpoch 25/100\n200/200 [==============================] - 11s 53ms/step - loss: 1.4920 - accuracy: 0.4134 - val_loss: 1.7929 - val_accuracy: 0.3425\nEpoch 26/100\n200/200 [==============================] - 11s 55ms/step - loss: 1.4437 - accuracy: 0.4359 - val_loss: 1.8621 - val_accuracy: 0.3225\nEpoch 27/100\n200/200 [==============================] - 10s 52ms/step - loss: 1.4009 - accuracy: 0.4538 - val_loss: 1.8790 - val_accuracy: 0.3088\nEpoch 28/100\n200/200 [==============================] - 11s 55ms/step - loss: 1.3912 - accuracy: 0.4750 - val_loss: 1.8892 - val_accuracy: 0.3200\nEpoch 29/100\n200/200 [==============================] - 11s 56ms/step - loss: 1.3346 - accuracy: 0.4806 - val_loss: 1.9547 - val_accuracy: 0.3262\nEpoch 30/100\n200/200 [==============================] - 11s 55ms/step - loss: 1.2741 - accuracy: 0.5063 - val_loss: 2.0711 - val_accuracy: 0.3050\nEpoch 31/100\n200/200 [==============================] - 11s 55ms/step - loss: 1.2288 - accuracy: 0.5294 - val_loss: 2.4272 - val_accuracy: 0.2338\nEpoch 32/100\n200/200 [==============================] - 11s 54ms/step - loss: 1.1346 - accuracy: 0.5569 - val_loss: 2.1165 - val_accuracy: 0.3462\nEpoch 33/100\n200/200 [==============================] - 11s 53ms/step - loss: 1.0822 - accuracy: 0.5947 - val_loss: 2.0324 - val_accuracy: 0.3038\nEpoch 34/100\n200/200 [==============================] - 10s 52ms/step - loss: 1.0113 - accuracy: 0.6212 - val_loss: 2.4782 - val_accuracy: 0.2950\nEpoch 35/100\n200/200 [==============================] - 11s 56ms/step - loss: 0.9368 - accuracy: 0.6503 - val_loss: 2.4069 - val_accuracy: 0.3187\nEpoch 36/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.8403 - accuracy: 0.6794 - val_loss: 2.2003 - val_accuracy: 0.3288\nEpoch 37/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.7562 - accuracy: 0.7106 - val_loss: 2.4089 - val_accuracy: 0.3775\nEpoch 38/100\n200/200 [==============================] - 11s 57ms/step - loss: 0.7344 - accuracy: 0.7312 - val_loss: 2.4891 - val_accuracy: 0.3613\nEpoch 39/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.6433 - accuracy: 0.7631 - val_loss: 2.5998 - val_accuracy: 0.3575\nEpoch 40/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.6039 - accuracy: 0.7912 - val_loss: 3.3671 - val_accuracy: 0.2650\nEpoch 41/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.5637 - accuracy: 0.7872 - val_loss: 2.9236 - val_accuracy: 0.3850\nEpoch 42/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.5092 - accuracy: 0.8138 - val_loss: 3.0948 - val_accuracy: 0.3512\nEpoch 43/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.4096 - accuracy: 0.8559 - val_loss: 3.4196 - val_accuracy: 0.2887\nEpoch 44/100\n200/200 [==============================] - 11s 54ms/step - loss: 0.3963 - accuracy: 0.8550 - val_loss: 3.6363 - val_accuracy: 0.3462\nEpoch 45/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.3176 - accuracy: 0.8900 - val_loss: 2.9621 - val_accuracy: 0.3462\nEpoch 46/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.3136 - accuracy: 0.8853 - val_loss: 4.1237 - val_accuracy: 0.3000\nEpoch 47/100\n200/200 [==============================] - 11s 55ms/step - loss: 0.3262 - accuracy: 0.8834 - val_loss: 3.8082 - val_accuracy: 0.3275\nEpoch 48/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.2610 - accuracy: 0.9044 - val_loss: 4.1426 - val_accuracy: 0.3487\nEpoch 49/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.2615 - accuracy: 0.9125 - val_loss: 3.6157 - val_accuracy: 0.3825\nEpoch 50/100\n200/200 [==============================] - 11s 54ms/step - loss: 0.1918 - accuracy: 0.9297 - val_loss: 3.4885 - val_accuracy: 0.3587\nEpoch 51/100\n200/200 [==============================] - 11s 56ms/step - loss: 0.2351 - accuracy: 0.9209 - val_loss: 4.0146 - val_accuracy: 0.3400\nEpoch 52/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.2280 - accuracy: 0.9234 - val_loss: 4.3689 - val_accuracy: 0.3000\nEpoch 53/100\n200/200 [==============================] - 11s 54ms/step - loss: 0.1766 - accuracy: 0.9366 - val_loss: 3.7169 - val_accuracy: 0.3725\nEpoch 54/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.1757 - accuracy: 0.9384 - val_loss: 4.0834 - val_accuracy: 0.3550\nEpoch 55/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.1454 - accuracy: 0.9522 - val_loss: 4.1613 - val_accuracy: 0.3887\nEpoch 56/100\n200/200 [==============================] - 11s 54ms/step - loss: 0.1583 - accuracy: 0.9459 - val_loss: 4.0094 - val_accuracy: 0.3462\nEpoch 57/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.1780 - accuracy: 0.9375 - val_loss: 3.9214 - val_accuracy: 0.3625\nEpoch 58/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.2190 - accuracy: 0.9278 - val_loss: 4.2578 - val_accuracy: 0.3713\nEpoch 59/100\n200/200 [==============================] - 11s 54ms/step - loss: 0.1126 - accuracy: 0.9634 - val_loss: 4.9226 - val_accuracy: 0.3650\nEpoch 60/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.1852 - accuracy: 0.9384 - val_loss: 4.4127 - val_accuracy: 0.3638\nEpoch 61/100\n200/200 [==============================] - 10s 51ms/step - loss: 0.1907 - accuracy: 0.9356 - val_loss: 4.1355 - val_accuracy: 0.3613\nEpoch 62/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.1483 - accuracy: 0.9478 - val_loss: 4.2798 - val_accuracy: 0.3725\nEpoch 63/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.1107 - accuracy: 0.9638 - val_loss: 4.1306 - val_accuracy: 0.3625\nEpoch 64/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.1174 - accuracy: 0.9638 - val_loss: 4.6371 - val_accuracy: 0.3562\nEpoch 65/100\n200/200 [==============================] - 11s 55ms/step - loss: 0.0907 - accuracy: 0.9716 - val_loss: 4.8220 - val_accuracy: 0.3625\nEpoch 66/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.1414 - accuracy: 0.9547 - val_loss: 5.2283 - val_accuracy: 0.3375\nEpoch 67/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.1118 - accuracy: 0.9609 - val_loss: 4.5350 - val_accuracy: 0.3550\nEpoch 68/100\n200/200 [==============================] - 11s 54ms/step - loss: 0.2143 - accuracy: 0.9278 - val_loss: 4.4489 - val_accuracy: 0.3700\nEpoch 69/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.1467 - accuracy: 0.9484 - val_loss: 4.4971 - val_accuracy: 0.3650\nEpoch 70/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.1183 - accuracy: 0.9609 - val_loss: 4.2635 - val_accuracy: 0.3762\nEpoch 71/100\n200/200 [==============================] - 11s 54ms/step - loss: 0.0623 - accuracy: 0.9784 - val_loss: 4.5455 - val_accuracy: 0.3438\nEpoch 72/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.1126 - accuracy: 0.9659 - val_loss: 4.8846 - val_accuracy: 0.3025\nEpoch 73/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.0603 - accuracy: 0.9800 - val_loss: 4.9448 - val_accuracy: 0.3800\nEpoch 74/100\n200/200 [==============================] - 11s 54ms/step - loss: 0.1479 - accuracy: 0.9522 - val_loss: 5.1124 - val_accuracy: 0.2925\nEpoch 75/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.2246 - accuracy: 0.9281 - val_loss: 4.2202 - val_accuracy: 0.3850\nEpoch 76/100\n200/200 [==============================] - 11s 56ms/step - loss: 0.1143 - accuracy: 0.9644 - val_loss: 4.3070 - val_accuracy: 0.3713\nEpoch 77/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.1143 - accuracy: 0.9659 - val_loss: 4.5797 - val_accuracy: 0.3738\nEpoch 78/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.1312 - accuracy: 0.9572 - val_loss: 5.1297 - val_accuracy: 0.3150\nEpoch 79/100\n200/200 [==============================] - 11s 57ms/step - loss: 0.0916 - accuracy: 0.9684 - val_loss: 4.9419 - val_accuracy: 0.3650\nEpoch 80/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.1600 - accuracy: 0.9459 - val_loss: 4.6343 - val_accuracy: 0.3487\nEpoch 81/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.0547 - accuracy: 0.9850 - val_loss: 4.5680 - val_accuracy: 0.3825\nEpoch 82/100\n200/200 [==============================] - 11s 54ms/step - loss: 0.0490 - accuracy: 0.9847 - val_loss: 5.6787 - val_accuracy: 0.3550\nEpoch 83/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.1247 - accuracy: 0.9597 - val_loss: 4.6072 - val_accuracy: 0.3600\nEpoch 84/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.0915 - accuracy: 0.9688 - val_loss: 5.2820 - val_accuracy: 0.3400\nEpoch 85/100\n200/200 [==============================] - 11s 55ms/step - loss: 0.0756 - accuracy: 0.9753 - val_loss: 4.7696 - val_accuracy: 0.4150\nEpoch 86/100\n200/200 [==============================] - 11s 53ms/step - loss: 0.1296 - accuracy: 0.9600 - val_loss: 5.2222 - val_accuracy: 0.3537\nEpoch 87/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.1914 - accuracy: 0.9450 - val_loss: 5.3869 - val_accuracy: 0.3638\nEpoch 88/100\n200/200 [==============================] - 11s 54ms/step - loss: 0.1327 - accuracy: 0.9575 - val_loss: 4.8658 - val_accuracy: 0.3713\nEpoch 89/100\n200/200 [==============================] - 11s 55ms/step - loss: 0.0772 - accuracy: 0.9762 - val_loss: 5.4146 - val_accuracy: 0.3575\nEpoch 90/100\n200/200 [==============================] - 11s 55ms/step - loss: 0.0740 - accuracy: 0.9759 - val_loss: 4.6520 - val_accuracy: 0.4000\nEpoch 91/100\n200/200 [==============================] - 11s 54ms/step - loss: 0.0819 - accuracy: 0.9722 - val_loss: 5.0744 - val_accuracy: 0.3300\nEpoch 92/100\n200/200 [==============================] - 11s 55ms/step - loss: 0.0710 - accuracy: 0.9769 - val_loss: 5.2299 - val_accuracy: 0.3550\nEpoch 93/100\n200/200 [==============================] - 11s 55ms/step - loss: 0.1116 - accuracy: 0.9638 - val_loss: 5.0792 - val_accuracy: 0.3738\nEpoch 94/100\n200/200 [==============================] - 11s 56ms/step - loss: 0.0805 - accuracy: 0.9766 - val_loss: 4.7297 - val_accuracy: 0.4025\nEpoch 95/100\n200/200 [==============================] - 11s 55ms/step - loss: 0.0667 - accuracy: 0.9800 - val_loss: 4.9443 - val_accuracy: 0.3700\nEpoch 96/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.1356 - accuracy: 0.9600 - val_loss: 4.5709 - val_accuracy: 0.3525\nEpoch 97/100\n200/200 [==============================] - 11s 56ms/step - loss: 0.0972 - accuracy: 0.9681 - val_loss: 5.7682 - val_accuracy: 0.3512\nEpoch 98/100\n200/200 [==============================] - 10s 52ms/step - loss: 0.0405 - accuracy: 0.9875 - val_loss: 5.1754 - val_accuracy: 0.3900\nEpoch 99/100\n200/200 [==============================] - 11s 55ms/step - loss: 0.0497 - accuracy: 0.9828 - val_loss: 5.6939 - val_accuracy: 0.3350\nEpoch 100/100\n200/200 [==============================] - 11s 57ms/step - loss: 0.1089 - accuracy: 0.9650 - val_loss: 4.7241 - val_accuracy: 0.3575\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fc7736a53d0>"},"metadata":{}}]}]}